{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"True\"\n",
    "\n",
    "api_key = getpass.getpass(prompt= \"Enter your api key: \")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading Tavily api key\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()\n",
    "#Importing Tavily\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = TavilySearchResults(max_results= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.linkedin.com/posts/keside-onyeocha-bb48b9298_startups-tech-innovation-activity-7199779056173600769-ZN3A',\n",
       "  'content': 'I&#39;ve been reflecting a lot lately on the choice between building a startup and joining a big tech company. The Lightcone podcast recently provided some‚Ä¶'},\n",
       " {'url': 'https://ng.linkedin.com/in/keside-onyeocha-bb48b9298',\n",
       "  'content': 'Liked by Keside Onyeocha. Founder of Cave.AI Hub || Researcher & Algorithm Development & Artificial intelligence & Natural Language Processing & AI Researcher & Predictive Analytics ¬∑ Passionate about leveraging machine learning to solve real-world challenges.<br><br>As a skilled Machine Learning Engineer, I specialize in building advanced ...'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.invoke(\"who is Keside Onyeocha Olatunbosun?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "doc = loader.load()\n",
    "\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000, chunk_overlap = 200 \n",
    ").split_documents(doc)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"output\": \"Welcome to LangSmith\"},        {\"output\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(    lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here    data=dataset_name, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | ƒü≈∏¬¶≈ì√Ø¬∏ÔøΩƒü≈∏‚Ä∫\\xa0√Ø¬∏ÔøΩ LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'}),\n",
       " Document(page_content='\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | ƒü≈∏¬¶≈ì√Ø¬∏ÔøΩƒü≈∏‚Ä∫\\xa0√Ø¬∏ÔøΩ LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'}),\n",
       " Document(page_content='score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright √Ç¬© 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | ƒü≈∏¬¶≈ì√Ø¬∏ÔøΩƒü≈∏‚Ä∫\\xa0√Ø¬∏ÔøΩ LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'}),\n",
       " Document(page_content='= traceable(async (user_input) => {    const result = await client.chat.completions.create({        messages: [{ role: \"user\", content: user_input }],        model: \"gpt-3.5-turbo\",    });    return result.choices[0].message.content;});await pipeline(\"Hello, world!\")// Out: Hello there! How can I assist you today?View a sample output trace.Learn more about tracing in the how-to guides.5. Run your first evaluation√¢‚Ç¨‚ÄπEvaluation requires a system to test, data to serve as test cases, and optionally evaluators to grade the results. Here we use a built-in accuracy evaluator.PythonTypeScriptfrom langsmith import Clientfrom langsmith.evaluation import evaluateclient = Client()# Define dataset: these are your test casesdataset_name = \"Sample Dataset\"dataset = client.create_dataset(dataset_name, description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | ƒü≈∏¬¶≈ì√Ø¬∏ÔøΩƒü≈∏‚Ä∫\\xa0√Ø¬∏ÔøΩ LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"how to upload a dataset?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [results, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "response = model.invoke([HumanMessage(content = \"Hi\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content String: Hello! How can I assist you today?\n",
      "toolcalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke([HumanMessage(content = \"Hi\")])\n",
    "print(f\"Content String: {response.content}\")\n",
    "print(f\"toolcalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'average price of an apartment in New York'}, 'id': 'call_N0T83RVrOYRFQnQYqnYp8Jod'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"How much is an regular sized apartment in newyork?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_tool_calling_executor will call .bind_tools for us under the hood.\n",
    "from langgraph.prebuilt import chat_agent_executor\n",
    "agent_executor = chat_agent_executor.create_tool_calling_executor(model, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi!?', id='7079d83d-8163-44c0-bf75-55d23bb41f1c'),\n",
       "  AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 129, 'total_tokens': 139}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-79c8041b-6e33-40ff-9451-5de889462bc7-0')]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content = \"Hi!?\")]})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='how can langsmith help with testing?', id='9270a3cd-88e3-43b3-ad7d-a464ad21766b'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_zzs7JmFdkSXXVo3pTQzoA8Ad', 'function': {'arguments': '{\\n  \"query\": \"how can LangSmith help with testing\"\\n}', 'name': 'langsmith_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 135, 'total_tokens': 157}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-59fdd717-dfd2-4edf-9992-d7b3c94dc281-0', tool_calls=[{'name': 'langsmith_search', 'args': {'query': 'how can LangSmith help with testing'}, 'id': 'call_zzs7JmFdkSXXVo3pTQzoA8Ad'}]),\n",
       "  ToolMessage(content='Get started with LangSmith | ƒü≈∏¬¶≈ì√Ø¬∏ÔøΩƒü≈∏‚Ä∫\\xa0√Ø¬∏ÔøΩ LangSmith\\n\\nSkip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith√¢‚Ç¨‚ÄπPythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key√¢‚Ç¨‚ÄπTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment√¢‚Ç¨‚ÄπShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it\\'s not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace√¢‚Ç¨‚ÄπWe provide multiple ways to log traces to LangSmith. Below, we\\'ll highlight\\n\\nscore: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright √Ç¬© 2024 LangChain, Inc.\\n\\n\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:', name='langsmith_search', id='e2e05937-710b-4b71-8a05-23080a92dc5d', tool_call_id='call_zzs7JmFdkSXXVo3pTQzoA8Ad'),\n",
       "  AIMessage(content='LangSmith is a platform designed for building production-grade Language Models (LLM) applications. It provides a way to closely monitor and evaluate your application, which can help ensure fast and reliable deployment. \\n\\nKey features that can help with testing include:\\n\\n1. **Tracing**: You can log traces to LangSmith, which can give you detailed insights into your application\\'s behavior.\\n\\n2. **Evaluation**: LangSmith provides a way to define and run evaluations. You can define your test cases (or \"examples\") and evaluators. An evaluator is a function that gets a run and an example, and returns an evaluation result, which contains a key and a score. The score indicates how well the run\\'s output matches the example\\'s output.\\n\\nFor instance, you can easily create a dataset for your test cases and create examples in it. Then, you can define an evaluator function that returns an exact match score, which is 1 if the run\\'s output is the same as the example\\'s output, and 0 otherwise. Then, you can use LangSmith\\'s `evaluate` function to execute the evaluation.\\n\\nThis way, LangSmith can help you ensure that your LLM application is working as expected and make improvements as necessary.', response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 841, 'total_tokens': 1088}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-dbec8868-ae19-4ed1-8202-b2c014eb702c-0')]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets retrieve\n",
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content = \"how can langsmith help with testing?\")]}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='how can langsmith help with testing?', id='8534c119-76c1-4087-a5a5-c49f563e1b22'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_sQ9pBCM8mTe3J0zmlrq9ZWay', 'function': {'arguments': '{\\n  \"query\": \"how can LangSmith help with testing\"\\n}', 'name': 'langsmith_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 135, 'total_tokens': 157}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6f91b136-8e56-461a-9bdc-f15803cf9e23-0', tool_calls=[{'name': 'langsmith_search', 'args': {'query': 'how can LangSmith help with testing'}, 'id': 'call_sQ9pBCM8mTe3J0zmlrq9ZWay'}]),\n",
       " ToolMessage(content='Get started with LangSmith | ƒü≈∏¬¶≈ì√Ø¬∏ÔøΩƒü≈∏‚Ä∫\\xa0√Ø¬∏ÔøΩ LangSmith\\n\\nSkip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith√¢‚Ç¨‚ÄπPythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key√¢‚Ç¨‚ÄπTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment√¢‚Ç¨‚ÄπShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it\\'s not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace√¢‚Ç¨‚ÄπWe provide multiple ways to log traces to LangSmith. Below, we\\'ll highlight\\n\\nscore: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright √Ç¬© 2024 LangChain, Inc.\\n\\n\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:', name='langsmith_search', id='03415528-db6f-4ae2-a460-94358f95f98c', tool_call_id='call_sQ9pBCM8mTe3J0zmlrq9ZWay'),\n",
       " AIMessage(content='LangSmith is a platform designed to help with the development of production-grade Language Learning Model (LLM) applications. It allows you to closely monitor and evaluate your application, which can be extremely beneficial during testing phases. Here are some ways LangSmith can assist with testing:\\n\\n1. **Trace Logging**: LangSmith provides multiple ways to log traces which can be useful in identifying and resolving issues during testing.\\n\\n2. **Evaluation Tools**: LangSmith provides tools to define and run evaluations. You can define test cases as datasets and use evaluators to compare the output of your program against expected results. The example shows an exact match evaluator that checks if the output matches the expected output exactly, but you can define your own evaluators to suit your testing requirements.\\n\\n3. **Environment Setup**: LangSmith also provides an easy way to set up your testing environment. \\n\\nRemember, LangSmith is a standalone platform and does not require the use of LangChain.', response_metadata={'token_usage': {'completion_tokens': 190, 'prompt_tokens': 841, 'total_tokens': 1031}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-216242fa-d066-41de-8ab4-7b8c6f7ee97e-0')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"how can langsmith help with testing?\")]}\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_JmrD27nT8qqUATp07PZ6fLRn', 'function': {'arguments': '{\\n  \"query\": \"current weather in Lagos Nigeria\"\\n}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 135, 'total_tokens': 158}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ac6bdddd-0e76-4ac1-894b-35024959f56c-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Lagos Nigeria'}, 'id': 'call_JmrD27nT8qqUATp07PZ6fLRn'}])]}}\n",
      "---\n",
      "{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'Lagos\\', \\'region\\': \\'Lagos\\', \\'country\\': \\'Nigeria\\', \\'lat\\': 6.45, \\'lon\\': 3.4, \\'tz_id\\': \\'Africa/Lagos\\', \\'localtime_epoch\\': 1716905797, \\'localtime\\': \\'2024-05-28 15:16\\'}, \\'current\\': {\\'last_updated_epoch\\': 1716905700, \\'last_updated\\': \\'2024-05-28 15:15\\', \\'temp_c\\': 32.0, \\'temp_f\\': 89.6, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 11.9, \\'wind_kph\\': 19.1, \\'wind_degree\\': 230, \\'wind_dir\\': \\'SW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.91, \\'precip_mm\\': 0.01, \\'precip_in\\': 0.0, \\'humidity\\': 75, \\'cloud\\': 50, \\'feelslike_c\\': 40.5, \\'feelslike_f\\': 104.9, \\'windchill_c\\': 29.9, \\'windchill_f\\': 85.7, \\'heatindex_c\\': 35.0, \\'heatindex_f\\': 94.9, \\'dewpoint_c\\': 24.1, \\'dewpoint_f\\': 75.4, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 6.0, \\'gust_mph\\': 17.3, \\'gust_kph\\': 27.8}}\"}, {\"url\": \"https://world-weather.info/forecast/nigeria/lagos/may-2024/\", \"content\": \"Detailed \\\\u26a1 Lagos Weather Forecast for May 2024 - day/night \\\\ud83c\\\\udf21\\\\ufe0f temperatures, precipitations - World-Weather.info. Add the current city. Search. Weather ... World; Nigeria; Weather in Lagos; Weather in Lagos in May 2024. Lagos Weather Forecast for May 2024 is based on long term prognosis and previous years\\' statistical data. 2015 2016 ...\"}]', name='tavily_search_results_json', id='973a0aee-7af3-4988-98f5-fafebe0e0c84', tool_call_id='call_JmrD27nT8qqUATp07PZ6fLRn')]}}\n",
      "---\n",
      "{'agent': {'messages': [AIMessage(content=\"The current weather in Lagos, Nigeria is partly cloudy with a temperature of 32.0¬∞C (89.6¬∞F). The wind is blowing from the southwest at a speed of 19.1 kph (11.9 mph). The humidity is at 75% and there is a UV index of 6.0. Please note that the weather conditions can change rapidly, so it's always best to check for the most current update. [Source](https://www.weatherapi.com/)\", response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 693, 'total_tokens': 794}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-07129912-78a8-45cb-8495-1f5716b7b4b4-0')]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content= \"what is the weather in Lagos, Nigeria\")]}\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "Starting tool: tavily_search_results_json with inputs: {'query': 'current weather in Lagos, Nigeria'}\n",
      "Done tool: tavily_search_results_json\n",
      "Tool output was: [{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Lagos', 'region': 'Lagos', 'country': 'Nigeria', 'lat': 6.45, 'lon': 3.4, 'tz_id': 'Africa/Lagos', 'localtime_epoch': 1716906241, 'localtime': '2024-05-28 15:24'}, 'current': {'last_updated_epoch': 1716905700, 'last_updated': '2024-05-28 15:15', 'temp_c': 32.0, 'temp_f': 89.6, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 11.9, 'wind_kph': 19.1, 'wind_degree': 230, 'wind_dir': 'SW', 'pressure_mb': 1013.0, 'pressure_in': 29.91, 'precip_mm': 0.01, 'precip_in': 0.0, 'humidity': 75, 'cloud': 50, 'feelslike_c': 40.5, 'feelslike_f': 104.9, 'windchill_c': 29.9, 'windchill_f': 85.7, 'heatindex_c': 35.0, 'heatindex_f': 94.9, 'dewpoint_c': 24.1, 'dewpoint_f': 75.4, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 6.0, 'gust_mph': 17.3, 'gust_kph': 27.8}}\"}, {'url': 'https://world-weather.info/forecast/nigeria/lagos/may-2024/', 'content': 'Extended weather forecast in Lagos. Hourly Week 10 days 14 days 30 days Year. Detailed ‚ö° Lagos Weather Forecast for May 2024 - day/night üå°Ô∏è temperatures, precipitations - World-Weather.info.'}]\n",
      "--\n",
      "The| current| weather| in| Lagos|,| Nigeria| is| partly| cloudy| with| a| temperature| of| |32|¬∞C| (|89|.|6|¬∞F|).| The| wind| is| coming| from| the| southwest| at| a| speed| of| |19|.|1| k|ph| (|11|.|9| mph|).| The| humidity| is| at| |75|%,| and| the| UV| index| is| |6|.|0|.| The| pressure| is| |101|3|.|0| mb|.| Please| note| that| this| information| is| as| of| the| last| update| at| |15|:|15| on| May| |28|,| |202|4|.| [|source|](|https|://|www|.weather|api|.com|/)|"
     ]
    }
   ],
   "source": [
    "async for event in agent_executor.astream_events(\n",
    "    {\"messages\": [HumanMessage(content=\"what is the weather in Lagos, Nigeria\")]}, version=\"v1\"\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the Agent is Stateless to add memory we add in a checkpoint using tread_id\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = chat_agent_executor.create_tool_calling_executor(\n",
    "    model, tools, checkpointer = memory\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Hello Keside! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 134, 'total_tokens': 146}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-edb9bf82-a666-418b-8ce9-8f333b8a0704-0')]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content = \"Hi, i am keside!\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Yes, I do remember. Your name is Keside. How can I assist you further?', response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 159, 'total_tokens': 179}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b9673b1c-02c9-4d6e-8176-980989796d1e-0')]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#to check if it stores value\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content = \"do you remember my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-openai) (0.2.1)\n",
      "Collecting openai<2.0.0,>=1.24.0\n",
      "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
      "     ------------------------------------ 320.6/320.6 kB 620.8 kB/s eta 0:00:00\n",
      "Collecting tiktoken<1,>=0.7\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-win_amd64.whl (798 kB)\n",
      "     -------------------------------------- 798.9/798.9 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (23.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (0.1.63)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (6.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (2.5.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (1.33)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.25.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.8.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2022.7.9)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.46->langchain-openai) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai) (2.14.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.24.0->langchain-openai) (0.4.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpcore->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (0.14.0)\n",
      "Installing collected packages: tiktoken, openai, langchain-openai\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.5.2\n",
      "    Uninstalling tiktoken-0.5.2:\n",
      "      Successfully uninstalled tiktoken-0.5.2\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.3.4\n",
      "    Uninstalling openai-1.3.4:\n",
      "      Successfully uninstalled openai-1.3.4\n",
      "Successfully installed langchain-openai-0.1.7 openai-1.30.3 tiktoken-0.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp310-cp310-win_amd64.whl (14.5 MB)\n",
      "     ---------------------------------------- 14.5/14.5 MB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.23.5)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
